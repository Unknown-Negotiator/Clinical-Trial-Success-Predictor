# Clinical Trial Success Predictor

Этот раздел проекта содержит данные, документы и артефакты, используемые
для построения RAG-компонента и последующего моделирования эффективности
конечных точек клинических испытаний в онкологии. Структура данных организована
так, чтобы обеспечить воспроизводимость, удобство навигации и возможность
переиспользования отдельных компонентов.

## Структура каталога
```text
notebooks/
└── RAG_clin_trials.ipynb    # ноутбук для сборки RAG-корпуса/индекса
data/
├── results/                 # опциональные логи батч-оценок (jsonl)
├── rag/
│   ├── rag_data/           # PDF-документы, используемые в качестве базы знаний
│   ├── rag_index/          # FAISS-индекс и метаданные чанков
│   └── docs_manifest.csv   # Манифест с метаинформацией по каждому документу
│
└── validation/             # Табличные данные и вспомогательные файлы для проверки моделей
```

## rag_data/

В эту папку входят документы, описывающие:
- дизайн и оценку клинических испытаний,
- регуляторные рекомендации FDA/EMA/ICH,
- методологии статистического анализа,
- классификации конечных точек и критериев ответа,
- исследования, посвящённые факторам успеха клинических программ.

Все документы проверены на релевантность, официальность источника
и дату публикации, чтобы использовать только данные, доступные
до момента появления описанных валидационных испытаний.

## Как формировался корпус RAG

Корпус был собран вручную и включает только авторитетные первоисточники,
которые реально используются в онкологических исследованиях и при регистрации
лекарственных препаратов. Подбор проводился поэтапно:

1. **Регуляторные документы (FDA, EMA, ICH)**  
   Были изучены официальные сайты глобальных регуляторов, откуда отобраны материалы уровня *guidance/guideline*.  
   Эти документы описывают:
   - допустимые конечные точки и критерии ответа,
   - статистические принципы (выбор контрольной группы, типы анализа),
   - правила работы с изображениями (BICR) и пропущенными данными.

   Они формируют «скелет» корпуса — нормативную основу, на которой строится вся логика клинической разработки.

2. **Научные обзоры (PubMed/PMC)**  
   Далее были отобраны обзорные статьи, объясняющие концепции конечных точек, принципы RECIST/iRECIST, подходы к оценке эффекта и интерпретации результатов.  
   Эти статьи дают понятные объяснения, которые помогают агенту не только извлекать факты, но и интерпретировать их в контексте клинической практики.

3. **Индустриальные аналитические отчёты (BIO и др.)**  
   Мы добавили исследования успешности клинических программ и факторов, влияющих на исход испытаний.  
   Они позволят агенту рассуждать о вероятностях успеха и типичных причинах провала исследований.

Документы отбирались по принципам:

- официальность или публикация в признанном научном источнике,
- фокус на онкологии или общие клинические статистические принципы,
- понятность и применимость для автоматического анализа,
- отсутствие вторичных пересказов и сомнительных материалов.

Таким образом, корпус RAG представляет собой тщательно составленную библиотеку,
которая объясняет как *проводятся*, так и *оцениваются* клинические испытания.
Она даёт модели «контекст профессионала» и улучшает качество выводов.

## docs_manifest.csv

Файл содержит метаданные для каждого документа:

- title — название,
- file_path — путь внутри rag_data/,
- url — источник,
- publication_date — дата публикации,
- source — организация/журнал,
- tags — тематические области.

Манифест используется для контроля состава корпуса и воспроизводимости
при пересборке индекса.

## rag_index/

Артефакты, необходимые для работы RAG:

- rag.faiss — векторный индекс (FAISS),
- rag_meta.jsonl — метаданные каждого чанка,
- embed_model.txt — информация о модели эмбеддингов,
- stats.json — сводка по количеству документов и чанков.

Текст документов извлекается, нормализуется и разбивается на чанки
(~900 токенов, перекрытие ~150). Эмбеддинги генерируются моделью intfloat/e5-base.

## validation/

Содержит табличные данные, которые используются как валидационная выборка,
а также вспомогательные файлы, необходимые для тестирования пайплайна.

## Логика обработки данных

1. Загрузка и проверка документов.
2. Описание каждого документа в docs_manifest.csv.
3. Извлечение текста, нормализация, чанкинг.
4. Генерация эмбеддингов и построение FAISS-индекса.
5. Использование индекса в RAG-компоненте для поиска релевантного контекста.

## Преимущества структуры

- Чёткое разделение сырьевых данных, индекса и метаданных.
- Возможность полностью пересобрать RAG-слой при обновлении документации.
- Прозрачный и контролируемый состав корпуса.
- Подготовленность структуры к интеграции в агентную систему.

## Добавление новых документов

1. Поместите PDF в rag/rag_data/.
2. Добавьте строку в docs_manifest.csv.
3. Пересоберите индекс.
4. Убедитесь, что обновились stats.json и rag_meta.jsonl.

## Streamlit MVP агент

В корне репозитория добавлен простой агент для оценки одной конечной точки с RAG, прайором и флагами (red/yellow/green).

### Запуск
```bash
pip install -r requirements.txt
export OPENAI_API_KEY=...             # ключ для совместимого OpenAI API
# при работе через Nebius:
# export OPENAI_BASE_URL="https://api.studio.nebius.ai/v1"
streamlit run app.py
```

### Что делает
- Выбираете endpoint из валидационного набора или задаёте JSON.
- Агент подбирает контекст из `data/rag/rag_index`, применяет прайор по фазе/типу endpoint, добавляет аккуратные штрафы (small-N survival, single-arm, refractory) и простой biomarker-флаг.
- LLM возвращает вероятностную оценку, флаги и обоснование с цитатами; система дополнительно блендит с прайором и показывает применённые штрафы/флаги.

### Оценка качества
- Плановый скрипт для прогона по `train_labels.csv` (precision/recall/F1) можно запускать отдельно; UI подходит для ручных проверок и демонстрации.

### Батч-оценка (скрипт)
```bash
# Пример: проверить 30 случайных конечных точек
conda activate clin-agent  # или ваша среда
export OPENAI_API_KEY=...       # + OPENAI_BASE_URL, OPENAI_MODEL при необходимости
python eval_agent.py --limit 30 --threshold 0.5 --output data/results/results.jsonl
```
Параметры:
- `--limit` (по умолчанию 20; -1 = все метки) — сколько конечных точек оценивать;
- `--threshold` — порог решения по смешанной вероятности;
- `--seed` — для случайной выборки;
- `--output` — путь для JSONL-логов с вероятностями/рационалами (опционально);
- `--model` — переопределить имя модели (если не использовать `OPENAI_MODEL`).

Примеры сохранённых логов лежат в `data/results/`.

### Предсказания для test.csv (submission)
```bash
conda activate clin-agent  # или ваша среда
export OPENAI_API_KEY=...       # + OPENAI_BASE_URL, OPENAI_MODEL при необходимости
python predict_test.py --output data/results/sample_submission.csv --details data/results/test_details.jsonl
```
Аргументы:
- `--output` — CSV в формате `endpoint_id,endpoint_criterion_met`;
- `--details` — опциональный JSONL с вероятностями/рационалами;
- `--threshold` — порог для бинарного решения (по умолчанию 0.5);
- `--limit` — подсчитать только первые N тестовых конечных точек (для отладки).
